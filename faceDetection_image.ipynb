{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "MS4hqOHgs8BB",
        "outputId": "3abe6709-8c1a-4fb2-a6bc-d5ab8220dcd9",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Action: age:  25%|█████████████████▊                                                     | 1/4 [00:00<00:00,  8.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resimler/26.jpg\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Action: race: 100%|██████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  5.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gender: Male\n",
            "Age: 25-32 years\n",
            "Race: middle eastern\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import math\n",
        "import argparse\n",
        "from deepface import DeepFace \n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "photo=[(\"Database/1.jpeg\"),(\"Database/2.jpeg\"),(\"Database/3.jpg\"),(\"Database/4.jpeg\"),(\"Database/5.jpg\"),(\"Database/6.jpg\"),\n",
        "      (\"Database/7.jpg\"),(\"Database/8.jpg\"),(\"Database/9.jpg\"),(\"Database/10.jpg\"),(\"Database/11.jpg\"),(\"Database/12.jpg\"),\n",
        "      (\"Database/13.jpg\"),(\"Database/14.jpg\"),(\"Database/15.jpg\"),(\"Database/16.jpg\"),(\"Database/17.jpg\"),(\"Database/18.jpg\"),\n",
        "      (\"Database/19.jpg\"), (\"Database/20.jpg\"),(\"Database/21.jpg\"),(\"Database/22.jpg\"),(\"Database/23.jpg\"),(\"Database/24.jpg\"),\n",
        "      (\"Database/25.jpg\")]\n",
        "\n",
        "a=0\n",
        "try:\n",
        "\n",
        "    for x in range(len(photo)):\n",
        "\n",
        "        print(photo[a])\n",
        "\n",
        "        def yuzTanimi(net, frame, conf_threshold=0.7):\n",
        "            frameOpencvDnn=frame.copy()\n",
        "            frameHeight=frameOpencvDnn.shape[0]\n",
        "            frameWidth=frameOpencvDnn.shape[1]\n",
        "            blob=cv2.dnn.blobFromImage(frameOpencvDnn, 1.0, (300, 300), [104, 117, 123], True, False)\n",
        "\n",
        "            net.setInput(blob)\n",
        "            detections=net.forward()\n",
        "            faceBoxes=[]\n",
        "            for i in range(detections.shape[2]):\n",
        "                confidence=detections[0,0,i,2]\n",
        "                if confidence>conf_threshold:\n",
        "                    x1=int(detections[0,0,i,3]*frameWidth)\n",
        "                    y1=int(detections[0,0,i,4]*frameHeight)\n",
        "                    x2=int(detections[0,0,i,5]*frameWidth)\n",
        "                    y2=int(detections[0,0,i,6]*frameHeight)\n",
        "                    faceBoxes.append([x1,y1,x2,y2])\n",
        "                    cv2.rectangle(frameOpencvDnn, (x1,y1), (x2,y2), (0,255,0), int(round(frameHeight/150)), 8)\n",
        "            return frameOpencvDnn,faceBoxes\n",
        "\n",
        "        parser = argparse.ArgumentParser()\n",
        "\n",
        "        parser.add_argument('--image')\n",
        "\n",
        "        args = parser.parse_args('')\n",
        "\n",
        "        img = cv2.imread(photo[a]) \n",
        "        color_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        prediction = DeepFace.analyze(color_img)\n",
        "\n",
        "        resultImg=photo[a]\n",
        "\n",
        "        faceProto=\"opencv_face_detector.pbtxt\"\n",
        "        faceModel=\"opencv_face_detector_uint8.pb\"\n",
        "        ageProto=\"age_deploy.prototxt\"\n",
        "        ageModel=\"age_net.caffemodel\"\n",
        "        genderProto=\"gender_deploy.prototxt\"\n",
        "        genderModel=\"gender_net.caffemodel\"\n",
        "\n",
        "        MODEL_MEAN_VALUES=(78.4263377603, 87.7689143744, 114.895847746)\n",
        "        ageList=['(0-2)', '(4-6)', '(8-12)', '(15-20)', '(25-32)', '(38-43)', '(48-53)', '(60-100)']\n",
        "        genderList=['Male','Female']\n",
        "\n",
        "        faceNet=cv2.dnn.readNet(faceModel,faceProto)\n",
        "        ageNet=cv2.dnn.readNet(ageModel,ageProto)\n",
        "        genderNet=cv2.dnn.readNet(genderModel,genderProto)\n",
        "\n",
        "        args.image=photo[a]\n",
        "\n",
        "        video=cv2.VideoCapture(args.image if args.image else 0)\n",
        "        padding=20\n",
        "        while cv2.waitKey(1)<0 :\n",
        "            hasFrame,frame=video.read()\n",
        "            if not hasFrame:\n",
        "                cv2.waitKey()\n",
        "                break\n",
        "\n",
        "            resultImg,faceBoxes=yuzTanimi(faceNet,frame)\n",
        "            if not faceBoxes:\n",
        "                print(\"Yüz algılanamadı\")\n",
        "\n",
        "            for faceBox in faceBoxes:\n",
        "                face=frame[max(0,faceBox[1]-padding):\n",
        "                           min(faceBox[3]+padding,frame.shape[0]-1),max(0,faceBox[0]-padding)\n",
        "                           :min(faceBox[2]+padding, frame.shape[1]-1)]\n",
        "\n",
        "                blob=cv2.dnn.blobFromImage(face, 1.0, (227,227), MODEL_MEAN_VALUES, swapRB=False)\n",
        "                genderNet.setInput(blob)\n",
        "                genderPreds=genderNet.forward()\n",
        "                gender=genderList[genderPreds[0].argmax()]\n",
        "                print(f'Gender: {gender}')\n",
        "\n",
        "                ageNet.setInput(blob)\n",
        "                agePreds=ageNet.forward()\n",
        "                age=ageList[agePreds[0].argmax()]\n",
        "                print(f'Age: {age[1:-1]} years')\n",
        "                print(f'Race: {prediction[\"dominant_race\"]}')\n",
        "\n",
        "\n",
        "                cv2.putText(resultImg, f'{gender}, {age},{prediction[\"dominant_race\"]}', (faceBox[0], faceBox[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,255), 2, cv2.LINE_AA)\n",
        "                cv2.imshow(\"Yuz Parametreleri ile Yas,Cinsiyet ve Irk Tahmini\", resultImg)\n",
        "\n",
        "        a=a+1\n",
        "    \n",
        "except:\n",
        "    print(\"Hatalı Yükleme\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "faceDetection-image.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}